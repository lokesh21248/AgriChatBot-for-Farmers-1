{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "b1.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "97rifHR2dyNQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tflearn\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vr8ayZRJdaiF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "e34bee1e-fa67-49ef-815b-03996549804f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521399223612,
          "user_tz": -330,
          "elapsed": 5903,
          "user": {
            "displayName": "Gaurav Agarwal",
            "photoUrl": "//lh6.googleusercontent.com/-lWcHWWBPevg/AAAAAAAAAAI/AAAAAAAAF_8/NRDhONXDYcc/s50-c-k-no/photo.jpg",
            "userId": "102008482759980640526"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "  Downloading tflearn-0.3.2.tar.gz (98kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->tflearn)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Running setup.py bdist_wheel for tflearn ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/fb/06/72/0478c938ca315c6fddcce8233b80ec91a115ce4496a27e8c90\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "clhQq6b8dq6l",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "a72b53a4-d814-4f6e-bba6-18bf8da2d3b5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521399395009,
          "user_tz": -330,
          "elapsed": 45099,
          "user": {
            "displayName": "Gaurav Agarwal",
            "photoUrl": "//lh6.googleusercontent.com/-lWcHWWBPevg/AAAAAAAAAAI/AAAAAAAAF_8/NRDhONXDYcc/s50-c-k-no/photo.jpg",
            "userId": "102008482759980640526"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n98XZIVmgyDY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EZGdflk0dyNW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('drive/Colab Notebooks/chatbot/intents.json') as json_data:\n",
        "    intents = json.load(json_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eHqXQt8HiAbx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {},
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b8cc6921-b96a-47be-f0d7-e96ef3ed8758",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521400421389,
          "user_tz": -330,
          "elapsed": 3346,
          "user": {
            "displayName": "Gaurav Agarwal",
            "photoUrl": "//lh6.googleusercontent.com/-lWcHWWBPevg/AAAAAAAAAAI/AAAAAAAAF_8/NRDhONXDYcc/s50-c-k-no/photo.jpg",
            "userId": "102008482759980640526"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /content/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "rLhPWTc_dyNc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "words=[]\n",
        "documents=[]\n",
        "classes=[]\n",
        "ignore_words=['?']\n",
        "\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "# loop through each sentence in our intents patterns\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "     # tokenize each word in the sentence\n",
        "         w=nltk.word_tokenize(pattern)\n",
        "     # add to our words list\n",
        "         words.extend(w)\n",
        "    # add to documents in our corpus\n",
        "         documents.append((w, intent['tag']))\n",
        "     # add to our classes list\n",
        "         if intent['tag'] not in classes:\n",
        "             classes.append(intent['tag'])\n",
        "        \n",
        "\n",
        "# stem and lower each word and remove duplicates\n",
        "words=[stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
        "words=sorted(list(set(words)))\n",
        "\n",
        "# remove duplicates\n",
        "classes=sorted(list(set(classes)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6qrJABUmdyNl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "88ab0643-0abc-4cfd-8435-6274cfd9f50a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521400435326,
          "user_tz": -330,
          "elapsed": 1732,
          "user": {
            "displayName": "Gaurav Agarwal",
            "photoUrl": "//lh6.googleusercontent.com/-lWcHWWBPevg/AAAAAAAAAAI/AAAAAAAAF_8/NRDhONXDYcc/s50-c-k-no/photo.jpg",
            "userId": "102008482759980640526"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print (len(documents), \"documents\",documents)\n",
        "print (len(classes), \"classes\", classes)\n",
        "print (len(words), \"unique stemmed words\", words)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25 documents [(['Hi'], 'greeting'), (['How', 'are', 'you'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Good', 'day'], 'greeting'), (['Namaste'], 'greeting'), (['Bye'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['TELL', 'ME', 'ABOUT', 'TAKING', 'SOIL', 'SAMPLE'], 'Soil Testing'), (['How', 'to', 'take', 'soil', 'sample', '?'], 'Soil Testing'), (['What', 'is', 'the', 'technique', 'used', 'in', 'taking', 'soil', 'sample'], 'Soil Testing'), (['TELL', 'ME', 'SOMETHING', 'ABOUT', 'NUTRIENT', 'MANAGEMENT', '?'], 'Nutrient Management'), (['What', 'are', 'some', 'ways', 'to', 'improve', 'nutrients', 'in', 'soil'], 'Nutrient Management'), (['How', 'to', 'manage', 'nutrients'], 'Nutrient Management'), (['TELL', 'ME', 'HOW', 'TO', 'CONTROL', 'INSECT', 'IN', 'WHEAT'], 'Plant Protection'), (['What', 'are', 'some', 'ways', 'to', 'control', 'insects', 'in', 'wheat'], 'Plant Protection'), (['GIVE', 'ME', 'SOME', 'INFORMATION', 'ON', 'SUBSIDIES'], 'Subsidy'), (['What', 'are', 'some', 'various', 'subsidy', 'data', '?'], 'Subsidy'), (['Farm', 'pond'], 'farm pond'), (['Solar', 'plant'], 'solar plant'), (['Pipe', 'line'], 'pipe line')]\n",
            "10 classes ['Nutrient Management', 'Plant Protection', 'Soil Testing', 'Subsidy', 'farm pond', 'goodbye', 'greeting', 'pipe line', 'solar plant', 'thanks']\n",
            "52 unique stemmed words [\"'s\", 'about', 'anyon', 'ar', 'bye', 'control', 'dat', 'day', 'farm', 'giv', 'good', 'goodby', 'hello', 'help', 'hi', 'how', 'improv', 'in', 'inform', 'insect', 'is', 'lat', 'lin', 'man', 'me', 'namast', 'nutry', 'on', 'pip', 'plant', 'pond', 'sampl', 'see', 'soil', 'sol', 'som', 'someth', 'subsidy', 'tak', 'techn', 'tel', 'thank', 'that', 'the', 'ther', 'to', 'us', 'vary', 'way', 'what', 'whe', 'you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pxmnwORmdyNv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# create our training data\n",
        "training=[]\n",
        "output=[]\n",
        "\n",
        "# create an empty array for our output\n",
        "output_empty=[0]*len(classes)\n",
        "\n",
        "# training set, bag of words for each sentence\n",
        "for doc in documents:\n",
        "    bag=[]\n",
        "     # list of tokenized words for the pattern\n",
        "    pattern_words=doc[0]\n",
        "    pattern_words=[stemmer.stem(word.lower()) for word in pattern_words]\n",
        "     # create our bag of words array\n",
        "    for w in words:\n",
        "        bag.append(1) if w in pattern_words else bag.append(0)\n",
        "        \n",
        "     # output is a '0' for each tag and '1' for current tag\n",
        "    output_row=list(output_empty)\n",
        "    output_row[classes.index(doc[1])]=1\n",
        "    \n",
        "    training.append([bag,output_row])\n",
        "    \n",
        "# shuffle our features and turn into np.array.\n",
        "random.shuffle(training)\n",
        "training=np.array(training)\n",
        "\n",
        "# create train and test lists\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ooE5alqwdyNy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {}
          ],
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "e5179af7-6ddb-427e-b00f-dd8a6024e7cd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521400525438,
          "user_tz": -330,
          "elapsed": 668,
          "user": {
            "displayName": "Gaurav Agarwal",
            "photoUrl": "//lh6.googleusercontent.com/-lWcHWWBPevg/AAAAAAAAAAI/AAAAAAAAF_8/NRDhONXDYcc/s50-c-k-no/photo.jpg",
            "userId": "102008482759980640526"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# reset underlying graph data\n",
        "tf.reset_default_graph()\n",
        "# Build neural network\n",
        "net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
        "net = tflearn.regression(net)\n",
        "\n",
        "# Define model and setup tensorboard\n",
        "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n",
        "# Start training (apply gradient descent algorithm)\n",
        "model.fit(train_x, train_y, n_epoch=1000, batch_size=8, show_metric=True)\n",
        "model.save('drive/Colab Notebooks/chatbot/model.tflearn')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 3999  | total loss: \u001b[1m\u001b[32m0.78752\u001b[0m\u001b[0m | time: 0.014s\n",
            "| Adam | epoch: 1000 | loss: 0.78752 - acc: 0.8998 -- iter: 24/25\n",
            "Training Step: 4000  | total loss: \u001b[1m\u001b[32m0.71449\u001b[0m\u001b[0m | time: 0.019s\n",
            "| Adam | epoch: 1000 | loss: 0.71449 - acc: 0.9098 -- iter: 25/25\n",
            "--\n",
            "INFO:tensorflow:/content/drive/Colab Notebooks/chatbot/model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BeUq74ISdyN5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# save all of our data structures\n",
        "import pickle\n",
        "pickle.dump({'words':words,'classes':classes,'train_x':train_x,'train_y':train_y},open('drive/Colab Notebooks/chatbot/training_data','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}